

<!DOCTYPE html>
<html lang="zh-CN" data-default-color-scheme=dark>



<head>
  <meta charset="UTF-8">
  <link rel="apple-touch-icon" sizes="76x76" href="/img/favicon.png">
  <link rel="icon" href="/img/favicon.png">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=5.0, shrink-to-fit=no">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  
    <meta http-equiv="Content-Security-Policy" content="upgrade-insecure-requests">
  
  <meta name="theme-color" content="#2f4154">
  <meta name="author" content="友纪V-λOP">
  <meta name="keywords" content="">
  
    <meta name="description" content="peek 一下 LangGraph 的基础">
<meta property="og:type" content="article">
<meta property="og:title" content="LangChain 学习 02——工作流，Chatbot">
<meta property="og:url" content="http://example.com/2025/03-29LangChain%E5%AD%A6%E4%B9%A002%E2%80%94%E2%80%94%E5%B7%A5%E4%BD%9C%E6%B5%81%EF%BC%8CChatbot/index.html">
<meta property="og:site_name" content="友纪V-λOP">
<meta property="og:description" content="peek 一下 LangGraph 的基础">
<meta property="og:locale" content="zh_CN">
<meta property="article:published_time" content="2025-03-29T05:20:00.000Z">
<meta property="article:modified_time" content="2025-03-29T05:22:44.138Z">
<meta property="article:author" content="友纪V-λOP">
<meta property="article:tag" content="AI">
<meta property="article:tag" content="Python">
<meta name="twitter:card" content="summary_large_image">
  
  
  <title>LangChain 学习 02——工作流，Chatbot - 友纪V-λOP</title>

  <link  rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4/dist/css/bootstrap.min.css" />


  <link  rel="stylesheet" href="https://cdn.jsdelivr.net/npm/github-markdown-css@4/github-markdown.min.css" />
  <link  rel="stylesheet" href="https://cdn.jsdelivr.net/npm/hint.css@2/hint.min.css" />

  
    
    
      
      <link  rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@10/styles/atom-one-dark.min.css" />
    
  

  
    <link  rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3/dist/jquery.fancybox.min.css" />
  


<!-- 主题依赖的图标库，不要自行修改 -->

<link rel="stylesheet" href="//at.alicdn.com/t/font_1749284_ba1fz6golrf.css">



<link rel="stylesheet" href="//at.alicdn.com/t/font_1736178_lbnruvf0jn.css">


<link  rel="stylesheet" href="/css/main.css" />

<!-- 自定义样式保持在最底部 -->


  <script id="fluid-configs">
    var Fluid = window.Fluid || {};
    var CONFIG = {"hostname":"example.com","root":"/","version":"1.8.14","typing":{"enable":true,"typeSpeed":70,"cursorChar":"_","loop":false},"anchorjs":{"enable":true,"element":"h1,h2,h3,h4,h5,h6","placement":"right","visible":"hover","icon":"#"},"progressbar":{"enable":true,"height_px":3,"color":"#29d","options":{"showSpinner":false,"trickleSpeed":100}},"copy_btn":true,"image_zoom":{"enable":true,"img_url_replace":["",""]},"toc":{"enable":true,"headingSelector":"h1,h2,h3,h4,h5,h6","collapseDepth":100},"lazyload":{"enable":false,"loading_img":"/img/loading.gif","onlypost":false,"offset_factor":2},"web_analytics":{"enable":false,"baidu":null,"google":null,"gtag":null,"tencent":{"sid":null,"cid":null},"woyaola":null,"cnzz":null,"leancloud":{"app_id":null,"app_key":null,"server_url":null,"path":"window.location.pathname","ignore_local":false}},"search_path":"/local-search.xml"};
  </script>
  <script  src="/js/utils.js" ></script>
  <script  src="/js/color-schema.js" ></script>
<!-- hexo injector head_end start -->
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.css">
<!-- hexo injector head_end end --><meta name="generator" content="Hexo 6.3.0"><link rel="alternate" href="/rss2.xml" title="友纪V-λOP" type="application/rss+xml">
</head>


<body>
  <header style="height: 70vh;">
    <nav id="navbar" class="navbar fixed-top  navbar-expand-lg navbar-dark scrolling-navbar">
  <div class="container">
    <a class="navbar-brand" href="/">
      <strong>友纪V-λOP的blog</strong>
    </a>

    <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse"
            data-target="#navbarSupportedContent"
            aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <div class="animated-icon"><span></span><span></span><span></span></div>
    </button>

    <!-- Collapsible content -->
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav ml-auto text-center">
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/">
                <i class="iconfont icon-home-fill"></i>
                首页
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/archives/">
                <i class="iconfont icon-archive-fill"></i>
                归档
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/tags/">
                <i class="iconfont icon-tags-fill"></i>
                标签
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/about/">
                <i class="iconfont icon-user-fill"></i>
                关于
              </a>
            </li>
          
        
        
          <li class="nav-item" id="search-btn">
            <a class="nav-link" target="_self" href="javascript:;" data-toggle="modal" data-target="#modalSearch" aria-label="Search">
              &nbsp;<i class="iconfont icon-search"></i>&nbsp;
            </a>
          </li>
        
        
          <li class="nav-item" id="color-toggle-btn">
            <a class="nav-link" target="_self" href="javascript:;" aria-label="Color Toggle">&nbsp;<i
                class="iconfont icon-dark" id="color-toggle-icon"></i>&nbsp;</a>
          </li>
        
      </ul>
    </div>
  </div>
</nav>

    <div class="banner" id="banner" parallax=true
         style="background: url('/img/default.png') no-repeat center center;
           background-size: cover;">
      <div class="full-bg-img">
        <div class="mask flex-center" style="background-color: rgba(0, 0, 0, 0.3)">
          <div class="page-header text-center fade-in-up">
            <span class="h2" id="subtitle" title="LangChain 学习 02——工作流，Chatbot">
              
            </span>

            
              <div class="mt-3">
  
  
    <span class="post-meta">
      <i class="iconfont icon-date-fill" aria-hidden="true"></i>
      <time datetime="2025-03-29 13:20" pubdate>
        2025年3月29日 下午
      </time>
    </span>
  
</div>

<div class="mt-1">
  
    <span class="post-meta mr-2">
      <i class="iconfont icon-chart"></i>
      19k 字
    </span>
  

  

  
  
</div>

            
          </div>

          
        </div>
      </div>
    </div>
  </header>

  <main>
    
      

<div class="container-fluid nopadding-x">
  <div class="row nomargin-x">
    <div class="d-none d-lg-block col-lg-2"></div>
    <div class="col-lg-8 nopadding-x-md">
      <div class="container nopadding-x-md" id="board-ctn">
        <div class="py-5" id="board">
          <article class="post-content mx-auto">
            <!-- SEO header -->
            <h1 style="display: none">LangChain 学习 02——工作流，Chatbot</h1>
            
            <div class="markdown-body">
              <p>通过看 LangChain 关于 Chatbot 的教程，peek 一下 LangGraph，以及做一个带会话记忆功能的 AI。</p>
<p>学习全新东西的时候，笔记也会做得一地鸡毛，这是挺正常的事情，不是吗？</p>
<h1 id="为何-LangChain-把记忆功能挪到-LangGraph？"><a href="#为何-LangChain-把记忆功能挪到-LangGraph？" class="headerlink" title="为何 LangChain 把记忆功能挪到 LangGraph？"></a>为何 LangChain 把记忆功能挪到 LangGraph？</h1><p>原来的记忆功能其实仍旧存在，但原因应该是，之前的实现不够通用且功能不够强大，而且似乎是和 Runnable 耦合的，<strong>开发者可能不太喜欢这种设计</strong>。他们重新在 LangGraph 中实现了更强大的记忆功能，包括时间旅行，提高通用性（支持任意自定义状态，工具调用记录……）。</p>
<h1 id="LangGraph-环境搭建"><a href="#LangGraph-环境搭建" class="headerlink" title="LangGraph 环境搭建"></a>LangGraph 环境搭建</h1><p>其实似乎不该在这里的时候就直接跳到 LangGraph……？<strong>LangChain 的 Chain 还没学到呢</strong>！</p>
<p>首先是关于 LangGraph 的环境搭建：</p>
<figure class="highlight sh"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs sh">pip install langchain-core langgraph&gt;0.2.27<br></code></pre></div></td></tr></table></figure>
<h1 id="简单复习"><a href="#简单复习" class="headerlink" title="简单复习"></a>简单复习</h1><p>这里也当作复习了——还记得 LangChain 是怎么用的吗？我记得 LangChain 提供了模型（继承自 Runnable）和消息的抽象，提供了 Document Loader，Embedding，Splitter，VectorStore，Retriever 这些抽象（只要记住 RAG 的流程，这个还挺容易回想的）。</p>
<p>但是，还记得怎么加载模型和直接使用它吗？（查看 import 列表的时候猛然意识到 langchain 的东西其实很少，我甚至有可能把所有东西都过一遍）</p>
<figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs python"><span class="hljs-keyword">import</span> langchain_deepseek<br><span class="hljs-keyword">from</span> langchain_core.messages <span class="hljs-keyword">import</span> HumanMessage<br><br>model = langchain_deepseek.ChatDeepSeek(model = <span class="hljs-string">&#x27;deepseek-chat&#x27;</span>)<br>result = model.invoke([<br>    (<span class="hljs-string">&#x27;human&#x27;</span>, <span class="hljs-string">&#x27;讲个笑话！&#x27;</span>),<br>    (<span class="hljs-string">&#x27;ai&#x27;</span>, <span class="hljs-string">&#x27;为什么 Java 程序员总带着眼镜？因为他们无法 C#！&#x27;</span>),<br>    HumanMessage(<span class="hljs-string">&#x27;再来一个！&#x27;</span>), <span class="hljs-comment"># 另一种定义消息的方式</span><br>])<br>result.content<br></code></pre></div></td></tr></table></figure>
<div class="hljs code-wrapper"><pre><code class="hljs">&#39;好的，再来一个程序员笑话：  \n\n **程序员去超市买菜**  \n 老婆打电话：“下班买五个包子，如果看到卖西瓜的，买一个。”  \n 结果程序员带回来一个包子。  \n 老婆问：“怎么只买一个？”  \n 程序员：“因为我看到卖西瓜的了。”  \n\n（逻辑没毛病，但今晚可能要跪键盘了😂）&#39;
</code></pre></div><p>很好。向量数据库那边的东西我就不再重新回忆了……等下面实际学 RAG 的时候再说。</p>
<p>回到正题，关于 LangGraph。</p>
<h1 id="初探工作流"><a href="#初探工作流" class="headerlink" title="初探工作流"></a>初探工作流</h1><p>首先有如下出发点：</p>
<ol>
<li>LangGraph 定义一个图，或者说工作流；大模型（在实操中是工具函数？），是这个图的节点</li>
<li><strong>图有全局状态</strong>，每个节点都能访问这个全局状态</li>
<li>工作流对节点内容不知晓，甚至不知道里面究竟有没有大模型</li>
</ol>
<p>直接拷贝官方样例代码：</p>
<figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs python"><span class="hljs-keyword">from</span> langgraph.checkpoint.memory <span class="hljs-keyword">import</span> MemorySaver<br><span class="hljs-keyword">from</span> langgraph.graph <span class="hljs-keyword">import</span> START, MessagesState, StateGraph<br><br><span class="hljs-comment"># Define a new graph</span><br>workflow = StateGraph(state_schema=MessagesState)<br><br><span class="hljs-comment"># Define the function that calls the model</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">call_model</span>(<span class="hljs-params">state: MessagesState</span>) -&gt; MessagesState:<br>    response = model.invoke(state[<span class="hljs-string">&quot;messages&quot;</span>])<br>    <span class="hljs-keyword">return</span> &#123;<span class="hljs-string">&quot;messages&quot;</span>: response&#125;<br><br><span class="hljs-comment"># Define the (single) node in the graph</span><br>workflow.add_edge(START, <span class="hljs-string">&quot;model&quot;</span>)<br>workflow.add_node(<span class="hljs-string">&quot;model&quot;</span>, call_model)<br><br>app = workflow.<span class="hljs-built_in">compile</span>(checkpointer=MemorySaver())<br></code></pre></div></td></tr></table></figure>
<p>注意到这里出现诸多新术语，State，MessagesState，StateGraph，Node，Worlflow，Checkpointer，MemorySaver，CompiledGraph。<strong>注意这里的 call_model 函数接受 state，但同时又返回 state</strong>（检查文档，是<code>State -&gt; Partial&lt;State&gt;</code>，这帮家伙原本写 ts 的？）。</p>
<p>注意到 LangGraph 提供了一个虚拟节点 START，这样就不需要提供一个<code>set_start</code>的方法了，直接使用 add_edge 去添加实际的头结点，非常聪明！但其实仍旧有相关方法 hhh。</p>
<p>但<strong>文档中没进一步解释这各部分是干嘛的</strong>，那我就把各部分跟着代码文档先 peek 一下再跟着它的步调来。</p>
<ol>
<li>State：指代的就是任意的状态，<strong>并不存在 State 这个抽象</strong></li>
<li>MessagesState：本质上是一个 TypedDict，只有一个字段 messages 存储会话历史；<strong>注意 MessagesState 本身是被工作流知晓的，而且工作流把它当成一个 Schema，这证明在工作流内部会有不止一个 MessagesState，实际上正是如此——对每一个会话（thread）（的每一个快照（checkpoint）？），肯定都会有一个自己的 MessagesState</strong>。</li>
<li>StateGraph：有状态的图，<strong>所有节点之间通过共享状态去进行交互</strong>。状态的内容比这里写的还更复杂，能提供一个 reducer 之类的，后面再表；注意这个图的定义非常松散——先添加了到 model 的边，再添加 model 到图里，估计图定义错了只有在运行时或者 compile 时报错</li>
<li>Checkpointer：应该是提供保存快照的功能。</li>
</ol>
<p>从字面意思上理解，上面定义了一个工作流，这个工作流实际上是一个有状态的图，但有趣的是，<strong>这个工作流实际上对大模型并不知晓，它只知道有个函数可以调，但不知道这个函数内部是什么魑魅魍魉</strong>。然后，<strong>这个工作流进行 compile，这个 compile 应该是检查和“实例化”图的“定义”，并将其编译成一个图的“实例”供后面使用，然后同时进行依赖注入</strong>，得到实际供使用的 app。</p>
<p>这里的图的“实例”命名为 app，显然它就是我们主要要使用的部分。我们来进行一些测试，先不考虑大模型：</p>
<figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs python"><span class="hljs-comment"># 使用函数定义，避免影响外部作用域</span><br><span class="hljs-keyword">from</span> typing <span class="hljs-keyword">import</span> TypedDict<br><span class="hljs-keyword">def</span> <span class="hljs-title function_">mygo</span>():<br>    <span class="hljs-keyword">class</span> <span class="hljs-title class_">MyState</span>(<span class="hljs-title class_ inherited__">TypedDict</span>):<br>        counter: <span class="hljs-built_in">int</span><br>    workflow = StateGraph(state_schema=MyState) <br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">inc</span>(<span class="hljs-params">state: MyState</span>) -&gt; MyState:<br>        <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> state.get(<span class="hljs-string">&#x27;counter&#x27;</span>):<br>            <span class="hljs-keyword">return</span> &#123;<span class="hljs-string">&#x27;counter&#x27;</span>: <span class="hljs-number">1</span>&#125;<br>        <span class="hljs-keyword">return</span> &#123;<span class="hljs-string">&#x27;counter&#x27;</span>: state[<span class="hljs-string">&#x27;counter&#x27;</span>] + <span class="hljs-number">1</span>&#125;<br>        <br>    workflow.add_node(<span class="hljs-string">&#x27;inc&#x27;</span>, inc)<br>    workflow.add_edge(START, <span class="hljs-string">&#x27;inc&#x27;</span>)<br>    app = workflow.<span class="hljs-built_in">compile</span>()<br>    <span class="hljs-comment"># 注意到这是无状态的</span><br>    display(app.invoke(&#123;&#125;))<br>    display(app.invoke(&#123;<span class="hljs-string">&#x27;counter&#x27;</span>: <span class="hljs-number">100</span>&#125;))<br>    display(app.invoke(&#123;<span class="hljs-string">&#x27;counter&#x27;</span>: <span class="hljs-number">101</span>&#125;))<br>    display(<span class="hljs-string">&#x27;---下面的是有状态的---&#x27;</span>)<br>    app = workflow.<span class="hljs-built_in">compile</span>(checkpointer=MemorySaver())<br>    <span class="hljs-comment"># 注意 MemorySaver 能够维持状态</span><br>    <span class="hljs-comment"># 两种方式都可以传递 thread_id</span><br>    display(app.invoke(&#123;&#125;, &#123;<span class="hljs-string">&quot;configurable&quot;</span>: &#123;<span class="hljs-string">&quot;thread_id&quot;</span>: <span class="hljs-number">123</span>&#125;&#125;))<br>    display(app.invoke(&#123;&#125;, &#123;<span class="hljs-string">&#x27;thread_id&#x27;</span>: <span class="hljs-number">123</span>&#125;))<br>    <span class="hljs-comment"># 注意可以给定初始值</span><br>    display(app.invoke(&#123;<span class="hljs-string">&#x27;counter&#x27;</span>: <span class="hljs-number">100</span>&#125;, &#123;<span class="hljs-string">&#x27;thread_id&#x27;</span>: <span class="hljs-number">345</span>&#125;))<br>    display(app.invoke(&#123;&#125;, &#123;<span class="hljs-string">&#x27;thread_id&#x27;</span>: <span class="hljs-number">345</span>&#125;))<br>    <span class="hljs-comment"># 注意用户的输入可以覆盖掉原状态</span><br>    display(app.invoke(&#123;&#125;, &#123;<span class="hljs-string">&#x27;thread_id&#x27;</span>: <span class="hljs-number">234</span>&#125;))<br>    display(app.invoke(&#123;<span class="hljs-string">&#x27;counter&#x27;</span>: <span class="hljs-number">200</span>&#125;, &#123;<span class="hljs-string">&#x27;thread_id&#x27;</span>: <span class="hljs-number">234</span>&#125;))<br>mygo()<br></code></pre></div></td></tr></table></figure>
<div class="hljs code-wrapper"><pre><code class="hljs">&#123;&#39;counter&#39;: 1&#125;
&#123;&#39;counter&#39;: 101&#125;
&#123;&#39;counter&#39;: 102&#125;
&#39;---下面的是有状态的---&#39;
&#123;&#39;counter&#39;: 1&#125;
&#123;&#39;counter&#39;: 2&#125;
&#123;&#39;counter&#39;: 101&#125;
&#123;&#39;counter&#39;: 102&#125;
&#123;&#39;counter&#39;: 1&#125;
&#123;&#39;counter&#39;: 201&#125;
</code></pre></div><p>好吧，注意到一点——<strong>图本身实际上是无状态的……把这个图称为 StateGraph，文档说是所有节点都共享状态，这个说法其实和实际行为是不搭的，并非如此——我们可以认为所有节点都是纯的（虽然不是那么纯……），因此整个图也是纯的</strong>。</p>
<p><strong>实际上没有所谓的共享状态</strong>——用户输入一个状态，这个状态在不同节点之间流转并返回，<strong>仅此而已</strong>。</p>
<p>但又注意到，我们使用 checkpointer 时，<strong>看上去就有状态了</strong>——这是因为这个 <strong>checkpointer 在维护状态</strong>，并且状态通过一个 thread_id 去进行标识，我们每次调用图的 invoke 方法的时候，实际上是先从 checkpointer 中取状态，然后再从用户输入中取状态，<strong>用用户的输入和 checkpointer 中的状态进行合并（和覆盖）</strong>。</p>
<p>所以，<strong>图其实是很轻量的，它无状态，只是一个流程的有机的序列，每个节点都很轻松，甚至可以看成是纯函数（只要它不报错，哈哈哈）</strong>。大概是这么个感觉。</p>
<pre><code class=" mermaid">flowchart LR
    用户输入 --&gt; Checkpointer --&gt; A[&quot;图（工作流）&quot;] --&gt; 输出
    输出 --&gt; Checkpointer
</code></pre>
<h1 id="Chatbot"><a href="#Chatbot" class="headerlink" title="Chatbot"></a>Chatbot</h1><p>上面对着官方样例代码做了一些分析和测试，感觉自己已经部分地学懂弄通了（结果是自己“发现”的，很有乐趣）。</p>
<p>现在，我们回到官方的示例，带着已有的知识重新检查上面的工作流的节点定义：</p>
<figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">call_model</span>(<span class="hljs-params">state: MessagesState</span>) -&gt; MessagesState:<br>    response: BaseMessage = model.invoke(state[<span class="hljs-string">&quot;messages&quot;</span>])<br>    <span class="hljs-keyword">return</span> &#123;<span class="hljs-string">&quot;messages&quot;</span>: response&#125;<br></code></pre></div></td></tr></table></figure>
<p>wait a minutes……我们知道，MessagesState 中，messages 字段是<code>list[BaseMessage]</code>啊？为什么这里 return 的是一个 BaseMessage？</p>
<p>这是因为，State 类允许配置一个<strong> reducer</strong>——它允许节点返回的值和实际的状态不同，reducer 把这个值和原来的状态做<strong>合并</strong>，实际上这个行为就像函数式编程里的 reduce。我们可以自己重新实现 MessagesState：</p>
<figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs python"><span class="hljs-keyword">from</span> typing_extensions <span class="hljs-keyword">import</span> Annotated<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">go</span>():<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">reducer</span>(<span class="hljs-params">acc: <span class="hljs-built_in">list</span>[<span class="hljs-built_in">int</span>], x: <span class="hljs-built_in">int</span></span>) -&gt; <span class="hljs-built_in">list</span>[<span class="hljs-built_in">int</span>]:<br>        <span class="hljs-keyword">if</span> acc <span class="hljs-keyword">is</span> <span class="hljs-literal">None</span>:<br>            <span class="hljs-keyword">return</span> [x]<br>        <span class="hljs-comment"># just like old times</span><br>        <span class="hljs-comment"># 最佳实践——每次都创建新的状态，不要更改原来的</span><br>        <span class="hljs-keyword">return</span> [*acc, x]<br>    <span class="hljs-keyword">class</span> <span class="hljs-title class_">MyState</span>(<span class="hljs-title class_ inherited__">TypedDict</span>):<br>        some_list: Annotated[<span class="hljs-built_in">list</span>[<span class="hljs-built_in">int</span>], reducer]<br><br>    workflow = StateGraph(state_schema=MyState)<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">append</span>(<span class="hljs-params">state: MyState</span>):<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;input state&#x27;</span>, state)<br>        <span class="hljs-keyword">return</span> &#123; <span class="hljs-string">&#x27;some_list&#x27;</span>: <span class="hljs-number">123</span> &#125; <span class="hljs-comment"># !</span><br>    workflow.add_node(<span class="hljs-string">&#x27;append&#x27;</span>, append)<br>    workflow.add_edge(START, <span class="hljs-string">&#x27;append&#x27;</span>)<br>    app = workflow.<span class="hljs-built_in">compile</span>(checkpointer=MemorySaver())<br>    display(app.invoke(&#123;<span class="hljs-string">&#x27;some_list&#x27;</span>: <span class="hljs-number">234</span>&#125;, &#123;<span class="hljs-string">&#x27;thread_id&#x27;</span>: <span class="hljs-number">1</span>&#125;))<br>    display(app.invoke(&#123;<span class="hljs-string">&#x27;some_list&#x27;</span>: <span class="hljs-number">555</span>&#125;, &#123;<span class="hljs-string">&#x27;thread_id&#x27;</span>: <span class="hljs-number">1</span>&#125;))<br>go()<br></code></pre></div></td></tr></table></figure>
<div class="hljs code-wrapper"><pre><code class="hljs">input state &#123;&#39;some_list&#39;: [234]&#125;


&#123;&#39;some_list&#39;: [234, 123]&#125;

input state &#123;&#39;some_list&#39;: [234, 123, 555]&#125;


&#123;&#39;some_list&#39;: [234, 123, 555, 123]&#125;
</code></pre></div><p>注意到——<strong>定义节点时，入参是 acc（原始状态），返回值是 x（状态增量）；使用工作流时，入参始终是 x（状态增量），返回值是 acc（原始状态）</strong>。下面实际使用官方样例进行对话。</p>
<figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs python">new_id = <span class="hljs-built_in">object</span>()<br>display(app.invoke(&#123;<span class="hljs-string">&#x27;messages&#x27;</span>: HumanMessage(<span class="hljs-string">&#x27;你好，我的名字是友纪&#x27;</span>)&#125;, &#123;<span class="hljs-string">&#x27;thread_id&#x27;</span>: new_id&#125;))<br>display(app.invoke(&#123;<span class="hljs-string">&#x27;messages&#x27;</span>: HumanMessage(<span class="hljs-string">&#x27;我的名字是什么？&#x27;</span>)&#125;, &#123;<span class="hljs-string">&#x27;thread_id&#x27;</span>: new_id&#125;))<br></code></pre></div></td></tr></table></figure>
<div class="hljs code-wrapper"><pre><code class="hljs">&#123;&#39;messages&#39;: [HumanMessage(content=&#39;你好，我的名字是友纪&#39;, additional_kwargs=&#123;&#125;, response_metadata=&#123;&#125;, id=&#39;2fcddbb2-0152-4367-85cd-3456e2ad7d30&#39;),
  AIMessage(content=&#39;你好，友纪！很高兴认识你～（*´▽｀*）  \n 请问今天有什么想聊的，或者需要帮忙的事情吗？无论是分享心情、提问，还是随便聊聊，我都在这里哦！✨&#39;, additional_kwargs=&#123;&#39;refusal&#39;: None&#125;, response_metadata=&#123;&#39;token_usage&#39;: &#123;&#39;completion_tokens&#39;: 48, &#39;prompt_tokens&#39;: 10, &#39;total_tokens&#39;: 58, &#39;completion_tokens_details&#39;: None, &#39;prompt_tokens_details&#39;: &#123;&#39;audio_tokens&#39;: None, &#39;cached_tokens&#39;: 0&#125;, &#39;prompt_cache_hit_tokens&#39;: 0, &#39;prompt_cache_miss_tokens&#39;: 10&#125;, &#39;model_name&#39;: &#39;deepseek-chat&#39;, &#39;system_fingerprint&#39;: &#39;fp_3d5141a69a_prod0225&#39;, &#39;finish_reason&#39;: &#39;stop&#39;, &#39;logprobs&#39;: None&#125;, id=&#39;run-c8258430-184c-4a25-8cd2-d32df0bcf56a-0&#39;, usage_metadata=&#123;&#39;input_tokens&#39;: 10, &#39;output_tokens&#39;: 48, &#39;total_tokens&#39;: 58, &#39;input_token_details&#39;: &#123;&#39;cache_read&#39;: 0&#125;, &#39;output_token_details&#39;: &#123;&#125;&#125;)]&#125;

&#123;&#39;messages&#39;: [HumanMessage(content=&#39;你好，我的名字是友纪&#39;, additional_kwargs=&#123;&#125;, response_metadata=&#123;&#125;, id=&#39;2fcddbb2-0152-4367-85cd-3456e2ad7d30&#39;),
  AIMessage(content=&#39;你好，友纪！很高兴认识你～（*´▽｀*）  \n 请问今天有什么想聊的，或者需要帮忙的事情吗？无论是分享心情、提问，还是随便聊聊，我都在这里哦！✨&#39;, additional_kwargs=&#123;&#39;refusal&#39;: None&#125;, response_metadata=&#123;&#39;token_usage&#39;: &#123;&#39;completion_tokens&#39;: 48, &#39;prompt_tokens&#39;: 10, &#39;total_tokens&#39;: 58, &#39;completion_tokens_details&#39;: None, &#39;prompt_tokens_details&#39;: &#123;&#39;audio_tokens&#39;: None, &#39;cached_tokens&#39;: 0&#125;, &#39;prompt_cache_hit_tokens&#39;: 0, &#39;prompt_cache_miss_tokens&#39;: 10&#125;, &#39;model_name&#39;: &#39;deepseek-chat&#39;, &#39;system_fingerprint&#39;: &#39;fp_3d5141a69a_prod0225&#39;, &#39;finish_reason&#39;: &#39;stop&#39;, &#39;logprobs&#39;: None&#125;, id=&#39;run-c8258430-184c-4a25-8cd2-d32df0bcf56a-0&#39;, usage_metadata=&#123;&#39;input_tokens&#39;: 10, &#39;output_tokens&#39;: 48, &#39;total_tokens&#39;: 58, &#39;input_token_details&#39;: &#123;&#39;cache_read&#39;: 0&#125;, &#39;output_token_details&#39;: &#123;&#125;&#125;),
  HumanMessage(content=&#39;我的名字是什么？&#39;, additional_kwargs=&#123;&#125;, response_metadata=&#123;&#125;, id=&#39;6bbda2b7-c15f-45f8-9721-bac2d8bb44e9&#39;),
  AIMessage(content=&#39;你的名字是**友纪**呀～刚刚告诉过我的，我可没有忘记哦！(◕‿◕✿)  \n 需要我用这个名字为你做点什么吗？比如：  \n- 记录你的偏好（喜欢的颜色、食物等等）  \n- 写一首藏头诗  \n- 或者…直接叫你“友纪酱”？ 😄&#39;, additional_kwargs=&#123;&#39;refusal&#39;: None&#125;, response_metadata=&#123;&#39;token_usage&#39;: &#123;&#39;completion_tokens&#39;: 75, &#39;prompt_tokens&#39;: 65, &#39;total_tokens&#39;: 140, &#39;completion_tokens_details&#39;: None, &#39;prompt_tokens_details&#39;: &#123;&#39;audio_tokens&#39;: None, &#39;cached_tokens&#39;: 0&#125;, &#39;prompt_cache_hit_tokens&#39;: 0, &#39;prompt_cache_miss_tokens&#39;: 65&#125;, &#39;model_name&#39;: &#39;deepseek-chat&#39;, &#39;system_fingerprint&#39;: &#39;fp_3d5141a69a_prod0225&#39;, &#39;finish_reason&#39;: &#39;stop&#39;, &#39;logprobs&#39;: None&#125;, id=&#39;run-48ee6d58-7171-4ccc-8e56-c05d5c90e412-0&#39;, usage_metadata=&#123;&#39;input_tokens&#39;: 65, &#39;output_tokens&#39;: 75, &#39;total_tokens&#39;: 140, &#39;input_token_details&#39;: &#123;&#39;cache_read&#39;: 0&#125;, &#39;output_token_details&#39;: &#123;&#125;&#125;)]&#125;
</code></pre></div><p>然后，如果要异步调用的话，就把 call_model 定义成 async 的，并使用图（Runnable）的<code>ainvoke</code>方法。</p>
<h2 id="如何设置系统-prompt？"><a href="#如何设置系统-prompt？" class="headerlink" title="如何设置系统 prompt？"></a>如何设置系统 prompt？</h2><p>在这里会有一个问题——我如何设置系统 prompt？<strong>系统 prompt 要存储进状态吗</strong>？答案是不必要——我们另外存系统 prompt，每次调用的时候把系统 prompt 放到最开始：</p>
<figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">call_model</span>(<span class="hljs-params">state: MessagesState</span>):<br>    real_messages = [SystemMessage(<span class="hljs-string">&#x27;...&#x27;</span>), *state[<span class="hljs-string">&#x27;messages&#x27;</span>]]<br>    response = model.invoke(real_messages)<br>    <span class="hljs-keyword">return</span> &#123;<span class="hljs-string">&quot;messages&quot;</span>: response&#125; <br></code></pre></div></td></tr></table></figure>
<p><strong>使用 promptTemplate 也是同样的思路</strong>：</p>
<figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs python"><span class="hljs-keyword">from</span> langchain_core.prompts <span class="hljs-keyword">import</span> ChatPromptTemplate, MessagesPlaceholder<br><br>prompt_template = ChatPromptTemplate.from_messages(<br>    [<br>        ( <span class="hljs-string">&quot;system&quot;</span>, <span class="hljs-string">&quot;...&quot;</span> ),<br>        MessagesPlaceholder(variable_name=<span class="hljs-string">&quot;messages&quot;</span>), <span class="hljs-comment"># 让它自动取 messages 字段</span><br>    ]<br>)<br><span class="hljs-keyword">def</span> <span class="hljs-title function_">call_model</span>(<span class="hljs-params">state: MessagesState</span>):<br>    real_messages = prompt_template.invoke(state)<br>    response = model.invoke(real_messages)<br>    <span class="hljs-keyword">return</span> &#123;<span class="hljs-string">&quot;messages&quot;</span>: response&#125; <br></code></pre></div></td></tr></table></figure>
<p>无论如何，系统 prompt 都不会被存进状态中。</p>
<h2 id="对话历史管理"><a href="#对话历史管理" class="headerlink" title="对话历史管理"></a>对话历史管理</h2><p>对于这种多轮对话的情况，一个很常见的需求就是对话历史管理——对话不能无限地拓展，不然 token 会用的越来越多，AI 的反应会越来越慢。通常有如下的需求：</p>
<ol>
<li>系统指令仍旧需要出现</li>
<li>第一条 prompt 通常需要是人类的</li>
<li>需要限制总 token 数量，通常是取最近的对话作为窗口</li>
</ol>
<p>LangChain 提供了一个 trim 会话历史的抽象（它仍旧是 Runnable）：</p>
<figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs python"><span class="hljs-keyword">from</span> langchain_core.messages <span class="hljs-keyword">import</span> SystemMessage, trim_messages, AIMessage<br><br>trimmer = trim_messages(<br>    max_tokens=<span class="hljs-number">65</span>,<br>    strategy=<span class="hljs-string">&quot;last&quot;</span>,<br>    token_counter=model,<br>    include_system=<span class="hljs-literal">True</span>,<br>    allow_partial=<span class="hljs-literal">False</span>,<br>    start_on=<span class="hljs-string">&quot;human&quot;</span>,<br>)<br><br>messages = [<br>    SystemMessage(content=<span class="hljs-string">&quot;you&#x27;re a good assistant&quot;</span>),<br>    HumanMessage(content=<span class="hljs-string">&quot;hi! I&#x27;m bob&quot;</span>),<br>    AIMessage(content=<span class="hljs-string">&quot;hi!&quot;</span>),<br>    HumanMessage(content=<span class="hljs-string">&quot;I like vanilla ice cream&quot;</span>),<br>    AIMessage(content=<span class="hljs-string">&quot;nice&quot;</span>),<br>    HumanMessage(content=<span class="hljs-string">&quot;whats 2 + 2&quot;</span>),<br>    AIMessage(content=<span class="hljs-string">&quot;4&quot;</span>),<br>    HumanMessage(content=<span class="hljs-string">&quot;thanks&quot;</span>),<br>    AIMessage(content=<span class="hljs-string">&quot;no problem!&quot;</span>),<br>    HumanMessage(content=<span class="hljs-string">&quot;having fun?&quot;</span>),<br>    AIMessage(content=<span class="hljs-string">&quot;yes!&quot;</span>),<br>]<br><br><span class="hljs-comment"># trimmer.invoke(messages) # 然而……我用的 deepseek 的实现似乎没有实现一些必须的算法导致这个会报错</span><br></code></pre></div></td></tr></table></figure>
<h2 id="流式输出"><a href="#流式输出" class="headerlink" title="流式输出"></a>流式输出</h2><p>这里就真的是魔法了…………………………它怎么做到的，它怎么做到的？？</p>
<p>stream 的默认 stream_mode 配置下，输出的会是同一条消息在每个步骤（node）下的响应；这里我们要的是流式输出，所以我们配置<code>stream_mode=&quot;messages&quot;</code>，这会使得会进行 token-by-token 的输出，注意到每次迭代会返回两个值——<strong>AI 的输出，以及是哪个步骤、节点输出的</strong>，后者在多节点的工作流中有意义。</p>
<p>那么，<strong>工作流究竟是如何通知大模型要使用流式输出的？能够猜测，背后肯定有何全局变量或者线程局部变量被修改了，让大模型开始进行流式处理；而且 LangGraph 把这个操作封装的很好，我们无法进行观察</strong>。</p>
<figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs python">new_id = <span class="hljs-built_in">object</span>()<br>i = <span class="hljs-number">0</span><br><span class="hljs-keyword">for</span> chunk, metadata <span class="hljs-keyword">in</span> app.stream(&#123;<span class="hljs-string">&#x27;messages&#x27;</span>: <span class="hljs-string">&#x27;你好&#x27;</span>&#125;, &#123;<span class="hljs-string">&#x27;thread_id&#x27;</span>: new_id&#125;, stream_mode=<span class="hljs-string">&quot;messages&quot;</span>):<br>    i += <span class="hljs-number">1</span><br>    <span class="hljs-keyword">if</span> i &gt; <span class="hljs-number">5</span>:<br>        <span class="hljs-keyword">break</span> <span class="hljs-comment"># 让回复更短一些！</span><br>    <span class="hljs-built_in">print</span>(chunk) <span class="hljs-comment"># 此时 AI 返回的是 AIMessageChunk 而非 AIMessage</span><br><br>    <span class="hljs-comment"># 尝试在这里这么干，就会发现这时候仍旧不是流式</span><br>    <span class="hljs-comment"># print(app.invoke(&#123;&#x27;messages&#x27;: HumanMessage(&#x27;我是谁？&#x27;)&#125;, &#123;&#x27;thread_id&#x27;: object()&#125;))</span><br>    <br>    <span class="hljs-built_in">print</span>(metadata)<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;---&#x27;</span>)<br></code></pre></div></td></tr></table></figure>
<div class="hljs code-wrapper"><pre><code class="hljs">content=&#39;&#39; additional_kwargs=&#123;&#125; response_metadata=&#123;&#125; id=&#39;run-1d69bb9d-f58e-4765-a28f-73c96a9a7812&#39;
&#123;&#39;langgraph_step&#39;: 1, &#39;langgraph_node&#39;: &#39;model&#39;, &#39;langgraph_triggers&#39;: (&#39;branch:to:model&#39;, &#39;start:model&#39;), &#39;langgraph_path&#39;: (&#39;__pregel_pull&#39;, &#39;model&#39;), &#39;langgraph_checkpoint_ns&#39;: &#39;model:f4a4c40f-ad74-c062-58df-99c93af1e3e2&#39;, &#39;checkpoint_ns&#39;: &#39;model:f4a4c40f-ad74-c062-58df-99c93af1e3e2&#39;, &#39;ls_provider&#39;: &#39;openai&#39;, &#39;ls_model_name&#39;: &#39;deepseek-chat&#39;, &#39;ls_model_type&#39;: &#39;chat&#39;, &#39;ls_temperature&#39;: None&#125;
---
content=&#39;你好&#39; additional_kwargs=&#123;&#125; response_metadata=&#123;&#125; id=&#39;run-1d69bb9d-f58e-4765-a28f-73c96a9a7812&#39;
&#123;&#39;langgraph_step&#39;: 1, &#39;langgraph_node&#39;: &#39;model&#39;, &#39;langgraph_triggers&#39;: (&#39;branch:to:model&#39;, &#39;start:model&#39;), &#39;langgraph_path&#39;: (&#39;__pregel_pull&#39;, &#39;model&#39;), &#39;langgraph_checkpoint_ns&#39;: &#39;model:f4a4c40f-ad74-c062-58df-99c93af1e3e2&#39;, &#39;checkpoint_ns&#39;: &#39;model:f4a4c40f-ad74-c062-58df-99c93af1e3e2&#39;, &#39;ls_provider&#39;: &#39;openai&#39;, &#39;ls_model_name&#39;: &#39;deepseek-chat&#39;, &#39;ls_model_type&#39;: &#39;chat&#39;, &#39;ls_temperature&#39;: None&#125;
---
content=&#39;！&#39; additional_kwargs=&#123;&#125; response_metadata=&#123;&#125; id=&#39;run-1d69bb9d-f58e-4765-a28f-73c96a9a7812&#39;
&#123;&#39;langgraph_step&#39;: 1, &#39;langgraph_node&#39;: &#39;model&#39;, &#39;langgraph_triggers&#39;: (&#39;branch:to:model&#39;, &#39;start:model&#39;), &#39;langgraph_path&#39;: (&#39;__pregel_pull&#39;, &#39;model&#39;), &#39;langgraph_checkpoint_ns&#39;: &#39;model:f4a4c40f-ad74-c062-58df-99c93af1e3e2&#39;, &#39;checkpoint_ns&#39;: &#39;model:f4a4c40f-ad74-c062-58df-99c93af1e3e2&#39;, &#39;ls_provider&#39;: &#39;openai&#39;, &#39;ls_model_name&#39;: &#39;deepseek-chat&#39;, &#39;ls_model_type&#39;: &#39;chat&#39;, &#39;ls_temperature&#39;: None&#125;
---
content=&#39;😊&#39; additional_kwargs=&#123;&#125; response_metadata=&#123;&#125; id=&#39;run-1d69bb9d-f58e-4765-a28f-73c96a9a7812&#39;
&#123;&#39;langgraph_step&#39;: 1, &#39;langgraph_node&#39;: &#39;model&#39;, &#39;langgraph_triggers&#39;: (&#39;branch:to:model&#39;, &#39;start:model&#39;), &#39;langgraph_path&#39;: (&#39;__pregel_pull&#39;, &#39;model&#39;), &#39;langgraph_checkpoint_ns&#39;: &#39;model:f4a4c40f-ad74-c062-58df-99c93af1e3e2&#39;, &#39;checkpoint_ns&#39;: &#39;model:f4a4c40f-ad74-c062-58df-99c93af1e3e2&#39;, &#39;ls_provider&#39;: &#39;openai&#39;, &#39;ls_model_name&#39;: &#39;deepseek-chat&#39;, &#39;ls_model_type&#39;: &#39;chat&#39;, &#39;ls_temperature&#39;: None&#125;
---
content=&#39; &#39; additional_kwargs=&#123;&#125; response_metadata=&#123;&#125; id=&#39;run-1d69bb9d-f58e-4765-a28f-73c96a9a7812&#39;
&#123;&#39;langgraph_step&#39;: 1, &#39;langgraph_node&#39;: &#39;model&#39;, &#39;langgraph_triggers&#39;: (&#39;branch:to:model&#39;, &#39;start:model&#39;), &#39;langgraph_path&#39;: (&#39;__pregel_pull&#39;, &#39;model&#39;), &#39;langgraph_checkpoint_ns&#39;: &#39;model:f4a4c40f-ad74-c062-58df-99c93af1e3e2&#39;, &#39;checkpoint_ns&#39;: &#39;model:f4a4c40f-ad74-c062-58df-99c93af1e3e2&#39;, &#39;ls_provider&#39;: &#39;openai&#39;, &#39;ls_model_name&#39;: &#39;deepseek-chat&#39;, &#39;ls_model_type&#39;: &#39;chat&#39;, &#39;ls_temperature&#39;: None&#125;
---
</code></pre></div><p>上面完成了 Chatbot 教程，但能够注意到，上面虽然使用了工作流，<strong>但这个工作流只有一个节点，我们实际上只是利用了工作流的 checkpointer 功能</strong>。而下面的 RAG 和 Agent，才是见真章的时候。</p>
<h1 id="Agent-一窥"><a href="#Agent-一窥" class="headerlink" title="Agent 一窥"></a>Agent 一窥</h1><p><strong>要尝试建立对 Agent 的系统的认知，以及知晓如何使用 Agent 去实现 RAG</strong>，这里只是一窥它的强大，后面得继续深入学习，但要避免把内容搞的太长。</p>
<p>LLM 自己除了生成文本无法做任何事情，而 Agent 则利用 LLM 作为<strong>推理引擎</strong>，使得能够使用 LLM 去进行操作，或者说能够让 LLM 能够操作外界。</p>
<p>下面的代码<strong>直接创建了一个 ReAct 的 agent，并依赖 tavily 搜索引擎提供联网搜索能力</strong>——LangGraph 直接提供了这个，prebuilt！牛逼。</p>
<figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs python"><span class="hljs-comment"># Import relevant functionality</span><br><span class="hljs-keyword">from</span> langchain_community.tools.tavily_search <span class="hljs-keyword">import</span> TavilySearchResults<br><span class="hljs-keyword">from</span> langchain_core.messages <span class="hljs-keyword">import</span> HumanMessage<br><span class="hljs-keyword">from</span> langgraph.checkpoint.memory <span class="hljs-keyword">import</span> MemorySaver<br><span class="hljs-keyword">from</span> langgraph.prebuilt <span class="hljs-keyword">import</span> create_react_agent<br><br><span class="hljs-comment"># Create the agent</span><br>memory = MemorySaver()<br>search = TavilySearchResults(max_results=<span class="hljs-number">2</span>)<br>tools = [search]<br><br><span class="hljs-comment"># holy...</span><br>agent_executor = create_react_agent(model, tools, checkpointer=memory)<br><br><span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> agent_executor.stream(&#123;<span class="hljs-string">&#x27;messages&#x27;</span>: HumanMessage(<span class="hljs-string">&#x27;现在三亚天气如何？&#x27;</span>)&#125;, &#123;<span class="hljs-string">&#x27;thread_id&#x27;</span>: <span class="hljs-number">1</span>&#125;, stream_mode=<span class="hljs-string">&#x27;values&#x27;</span>):<br>    i[<span class="hljs-string">&quot;messages&quot;</span>][-<span class="hljs-number">1</span>].pretty_print()<br></code></pre></div></td></tr></table></figure>
<div class="hljs code-wrapper"><pre><code class="hljs">================================[1m Human Message [0m=================================

现在武汉天气如何？
==================================[1m Ai Message [0m==================================
Tool Calls:
  tavily_search_results_json (call_0_132935db-b027-4038-ab81-3aa7e6511625)
 Call ID: call_0_132935db-b027-4038-ab81-3aa7e6511625
  Args:
    query: 武汉天气
=================================[1m Tool Message [0m=================================
Name: tavily_search_results_json

[&#123;&quot;title&quot;: &quot;武汉 - 中国气象局-天气预报-城市预报&quot;, &quot;url&quot;: &quot;https://weather.cma.cn/web/weather/57494.html&quot;, &quot;content&quot;: &quot;主站首页、n 领导主站、n 部门概况、n 新闻资讯、n 信息公开、n 服务办事、n 天气预报、n 首页、n 天气实况、n 气象公报、n 气象预警、n 城市预报、n 天气资讯、n 气象专题、n 气象科普、n 首页 国内 湖北 武汉、n 国内 \n|\n 湖北 \n|\n 武汉 \n 更新、n \n           \n7 天天气预报（2025/02/10 12:00 发布）\n 星期一、n02/10\n 晴、n 无持续风向、n 微风、n13℃\n0℃\n 多云、n 无持续风向、n 微风、n 星期二、n02/11\n 小雨、n 西南风、n 微风、n10℃\n6℃\n 小雨、n 西北风、n 微风、n 星期三、n02/12\n 小雨、n 北风、n 微风、n8℃\n2℃\n 晴、n 北风、n 微风、n 星期四、n02/13\n 阴、n 西南风、n 微风、n10℃\n2℃\n 小雨、n 东风、n 微风、n 星期五、n02/14\n 小雨、n 西北风、n 微风、n6℃\n4℃\n 小雨、n 西南风、n 微风、n 星期六、n02/15\n 晴、n 西南风、n 微风、n15℃\n0℃\n 多云、n 东风、n 微风、n 星期日、n02/16\n 晴、n 东北风、n 微风、n17℃\n0℃\n 晴、n 东风、n 微风、n 时间 17:00   20:00   23:00   02:00   05:00   08:00   11:00   14:00\n 天气 [...] 气温 9.1℃    2.6℃  南风  2 级&quot;, &quot;score&quot;: 0.79732054&#125;]
==================================[1m Ai Message [0m==================================

根据最新的天气预报：

- **今天（02/10）**：晴，气温在 0℃到 13℃之间，无持续风向，微风。
- **明天（02/11）**：小雨，气温在 6℃到 10℃之间，西南风转西北风，微风。
- **后天（02/12）**：小雨转晴，气温在 2℃到 8℃之间，北风，微风。

更多详细信息可以参考 [中国气象局](https://weather.cma.cn/web/weather/57494.html) 或 [墨迹天气](https://tianqi.moji.com/weather/china/hubei/wuhan)。
</code></pre></div><p>虽然它会回答错（因为查到的网站不行），但注意到它的可能性——<strong>一行代码带来 ReAct 模式，不需要自己去维护相关的 Prompt</strong>。</p>
<p>但这个教程只介绍了使用<code>create_react_agent</code>方法去创建一个 Agent，我想要更细节的内容，所以这里……不再深入了。</p>
<p>但这里仍旧提及一件事——<strong>tool 是直接绑定到 model 上的，这个功能是 LangChain 直接提供的，离开 LangGraph 也能用</strong>：</p>
<figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs python">model_with_tools = model.bind_tools([search]) <span class="hljs-comment"># 这个方法……似乎是纯的，会返回一个新的 Runnable</span><br><br>response: AIMessage = model_with_tools.invoke(<span class="hljs-string">&#x27;今天三亚天气如何？&#x27;</span>)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;ContentString: <span class="hljs-subst">&#123;response.content&#125;</span>&quot;</span>)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;ToolCalls: <span class="hljs-subst">&#123;response.tool_calls&#125;</span>&quot;</span>)<br></code></pre></div></td></tr></table></figure>
<div class="hljs code-wrapper"><pre><code class="hljs">ContentString: 
ToolCalls: [&#123;&#39;name&#39;: &#39;tavily_search_results_json&#39;, &#39;args&#39;: &#123;&#39;query&#39;: &#39;今天三亚天气&#39;&#125;, &#39;id&#39;: &#39;call_0_5ae8224b-2439-4afa-9d6e-35ccebd89617&#39;, &#39;type&#39;: &#39;tool_call&#39;&#125;]
</code></pre></div><p>实际上，<strong>这个功能来自 OpenAI 的 API 规范</strong>，兼容 OpenAI 的 API 的 AI 均能够使用此种方式。</p>
<p>但同时也注意——这里没有真的调用这个工具，<strong>AI 只是试图去调用它</strong>，真正调用这个工具是我们的“客户端”的任务，<strong>客户端调用工具后，将工具调用结果（成功或者失败）也放到会话历史中</strong>。</p>

            </div>
            <hr>
            <div>
              <div class="post-metas mb-3">
                
                
                  <div class="post-meta">
                    <i class="iconfont icon-tags"></i>
                    
                      <a class="hover-with-bg" href="/tags/AI/">AI</a>
                    
                      <a class="hover-with-bg" href="/tags/Python/">Python</a>
                    
                  </div>
                
              </div>
              
                <p class="note note-warning">
                  
                    本博客所有文章除特别声明外，均采用 <a target="_blank" href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh" rel="nofollow noopener noopener">CC BY-NC-SA 4.0 协议</a> ，转载请注明出处！
                  
                </p>
              
              
                <div class="post-prevnext">
                  <article class="post-prev col-6">
                    
                    
                  </article>
                  <article class="post-next col-6">
                    
                    
                      <a href="/2025/03-28%E7%BC%96%E7%A8%8B%E5%85%A5%E9%97%A802%E2%80%94%E2%80%94%E4%B8%BA%E4%BB%80%E4%B9%88%E6%98%AFPython%EF%BC%8C%E8%A1%A8%E8%BE%BE%E5%BC%8F%E5%92%8C%E8%AF%AD%E5%8F%A5/index.html">
                        <span class="hidden-mobile">编程入门 02——为什么是 Python，表达式和语句</span>
                        <span class="visible-mobile">下一篇</span>
                        <i class="iconfont icon-arrowright"></i>
                      </a>
                    
                  </article>
                </div>
              
            </div>

            
          </article>
        </div>
      </div>
    </div>
    
      <div class="d-none d-lg-block col-lg-2 toc-container" id="toc-ctn">
        <div id="toc">
  <p class="toc-header"><i class="iconfont icon-list"></i>&nbsp;目录</p>
  <div class="toc-body" id="toc-body"></div>
</div>

      </div>
    
  </div>
</div>

<!-- Custom -->


    

    
      <a id="scroll-top-button" aria-label="TOP" href="#" role="button">
        <i class="iconfont icon-arrowup" aria-hidden="true"></i>
      </a>
    

    
      <div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel"
     aria-hidden="true">
  <div class="modal-dialog modal-dialog-scrollable modal-lg" role="document">
    <div class="modal-content">
      <div class="modal-header text-center">
        <h4 class="modal-title w-100 font-weight-bold">搜索</h4>
        <button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body mx-3">
        <div class="md-form mb-5">
          <input type="text" id="local-search-input" class="form-control validate">
          <label data-error="x" data-success="v"
                 for="local-search-input">关键词</label>
        </div>
        <div class="list-group" id="local-search-result"></div>
      </div>
    </div>
  </div>
</div>
    

    
  </main>

  <footer class="text-center mt-5 py-3">
  <div class="footer-content">
     <a href="https://hexo.io" target="_blank" rel="nofollow noopener"><span>Hexo</span></a> <i class="iconfont icon-love"></i> <a href="https://github.com/fluid-dev/hexo-theme-fluid" target="_blank" rel="nofollow noopener"><span>Fluid</span></a> 
  </div>
  

  

  
</footer>


  <!-- SCRIPTS -->
  
  <script  src="https://cdn.jsdelivr.net/npm/nprogress@0/nprogress.min.js" ></script>
  <link  rel="stylesheet" href="https://cdn.jsdelivr.net/npm/nprogress@0/nprogress.min.css" />

  <script>
    NProgress.configure({"showSpinner":false,"trickleSpeed":100})
    NProgress.start()
    window.addEventListener('load', function() {
      NProgress.done();
    })
  </script>


<script  src="https://cdn.jsdelivr.net/npm/jquery@3/dist/jquery.min.js" ></script>
<script  src="https://cdn.jsdelivr.net/npm/bootstrap@4/dist/js/bootstrap.min.js" ></script>
<script  src="/js/events.js" ></script>
<script  src="/js/plugins.js" ></script>

<!-- Plugins -->


  <script  src="/js/local-search.js" ></script>





  



  
    <script  src="https://cdn.jsdelivr.net/npm/tocbot@4/dist/tocbot.min.js" ></script>
  
  
    <script  src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3/dist/jquery.fancybox.min.js" ></script>
  
  
    <script  src="https://cdn.jsdelivr.net/npm/anchor-js@4/anchor.min.js" ></script>
  
  
    <script defer src="https://cdn.jsdelivr.net/npm/clipboard@2/dist/clipboard.min.js" ></script>
  






  <script  src="https://cdn.jsdelivr.net/npm/typed.js@2/lib/typed.min.js" ></script>
  <script>
    (function (window, document) {
      var typing = Fluid.plugins.typing;
      var title = document.getElementById('subtitle').title;
      
        typing(title);
      
    })(window, document);
  </script>









  <script  src="https://cdn.jsdelivr.net/npm/mermaid@11/dist/mermaid.min.js" ></script>
  <script>
    if (window.mermaid) {
      mermaid.initialize({"theme":"default"});
    }
  </script>







<!-- 主题的启动项 保持在最底部 -->
<script  src="/js/boot.js" ></script>


<!-- hexo injector body_end start -->
<script src="/assets/prism-bundle.js"></script>
<script src="/assets/prism-plus.js" data-pjax=""></script>
<!-- hexo injector body_end end --></body>
</html>
